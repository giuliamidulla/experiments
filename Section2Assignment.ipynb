{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uUlNwMqnFrD"
      },
      "source": [
        "# Section 2 Assignment - NLP Deep Learning with CNNs and RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wHnGU9tnFrF"
      },
      "source": [
        "For this assignment, you need to use the code files provided in the [Section 2 folder on GitLab](https://gitlab.com/patrickdenny/mn5002-sem2-2022-2023/-/tree/main/Section%202) to build and test a **sentiment analyzer using CNNs and RNNs** and develop it according to the requirements set out in the [Rubric for the Assignment](https://sulis.ul.ie/portal/directtool/6ff19f6a-81c3-42ef-b7c8-0fee4a6ac74f/).\n",
        "\n",
        "In the [MN5002 Section 2 GitLab folder](https://gitlab.com/patrickdenny/mn5002-sem2-2022-2023/-/tree/main/Section%202), code has been provided for\n",
        "* **CNN based** sentiment analyzer generation on **Colab**\n",
        "* **RNN based** sentiment analyzer generation **locally**, because we are running into the common problem in deep learning, namely resource overhead (time/memory/computation) and while it is desirable to expose students to these issues it is undesirable to waste students' time trying to battle with resources when the intention is to teach you how it all works and you can make it work too.\n",
        "\n",
        "Note that you will have to change the directory names to match your own situation.\n",
        "\n",
        "Your homework submission should consist of\n",
        "* A version of this Jupyter Notebook file which should have your **student name and number** inside near the top\n",
        "* Code sections **followed by their output** as it may be difficult for the instructor to examine your specific dataset\n",
        "* Text sections elaborating the behaviour of each of your code sections and their outputs, with acknowledgements of any contributions from others\n",
        "\n",
        "You are encouraged to provide the neural networks that you have developed on Colab, **please use a sensible naming convention** for them. When you put them on GitLab, please provide a link in the Discussion along with a description of the network\n",
        "\n",
        "As part of your homework, you will need to use (either on Colab or locally) the following two compressed files :\n",
        "* [Stanford AI Sentiment Database](https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)\n",
        "* [Google News trained word vectors](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing)\n",
        "\n",
        "**Please do not submit their data, they are huge and it is unnecessary.**\n",
        "\n",
        "If you have any queries on this homework after you have referred to the [Rubric for the Assignment](https://sulis.ul.ie/portal/directtool/6ff19f6a-81c3-42ef-b7c8-0fee4a6ac74f/) and the [sample code on GitLab](https://gitlab.com/patrickdenny/mn5002-sem2-2022-2023/-/tree/main/Section%202), raise it in the [Section 2 Discussion Section](https://sulis.ul.ie/portal/directtool/955adf95-93a6-4eed-be7b-dad04bbf453c/)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giulia Midulla - 23330406\n",
        "\n",
        "For this assignment I chose to create a CNN with Google Colab.\n",
        "Unfortunately, I did not realise that it hadn't extracted most of the necessary training and test data. The model was severely undertrained, and my results did not make any sense. Once I was able to figure out the source of the problem I manually uploaded the unzipped files with Drive for Desktop, which was very time consuming.\n",
        "The assignment itself was very interesting, and I have done 5 different tests with different hyperparameters, in order to familiarise myself with CNNs and to find the best solution.\n",
        "\n",
        "##[Test 1](https://github.com/EMGrua/MN5002/blob/Giulia_Midulla_23330406/Section%202/Section_2_Giulia_Midulla_23330406_Test_1.ipynb)\n",
        "I ran this test with the preset values given in the assignment. I had 8 reviews in total. Out of these 8, 4 gave me the result I was expecting.\n",
        "`sample_2`, `test1`, `test2` and `test7` are very clear, and the model didn't have any issues understanding their sentiment.\n",
        "`test3` (This isn't the best movie of all time) was recognised as strongly positive, same as `test4` (This movie is as good as The Room), even though they are both negative. `test5` is somewhat contradictory, with the reviewer saying that the movie is considered good, but they disagree with it. The model seems to be confident that it is a positive review. Finally, `test6` compares the movie to many fun activities such as holding puppies, but without any explicit adjectives. The model recognises it as negative.\n",
        "##[Test 2](https://github.com/EMGrua/MN5002/blob/Giulia_Midulla_23330406/Section%202/Section_2_Giulia_Midulla_23330406_Test_2.ipynb)\n",
        "In this test I wanted to see what would happen if I reduced every hyperparameter to half. 6 out of 8 predictions were correct!\n",
        "`test3` and `test4` are still incorrectly recognised as positive, but the contradictory `test5` returns `0.57`, showing an indecision in the model that fits with the nature of the sentence. A similar thing can be said for `test6`: the lack of positive adjectives still doesn't give the model a strong confidence, but the review is nonetheless recognised as positive.\n",
        "##[Test 3](https://github.com/EMGrua/MN5002/blob/Giulia_Midulla_23330406/Section%202/Section_2_Giulia_Midulla_23330406_Test_3.ipynb)\n",
        "The aim of the third test was to see the consequences of overfitting. I returned all hyperparameters to the present values, but I increased the epochs to 10. 4 out of 8 predictions were correct. The model is a lot more confident, with the predictions being a lot closer to 0 and to 1 than in the previous cases. Unfortunately, this doesn't help the model recognise `test3` and `test4` as negative, and it recognises the ambiguous `test5` as a net positive. `test6` is again recognised incorrectly as negative. The increased confidence due to overfitting did not help in any way, and it ruined the sensitivity of the predictions.\n",
        "##[Test 4](https://github.com/EMGrua/MN5002/blob/Giulia_Midulla_23330406/Section%202/Section_2_Giulia_Midulla_23330406_Test_4.ipynb)\n",
        "In order to address the repeated issues with `test3`, `test4` and `test6`, I returned the hyperparameters to the present values, but doubled the number of filters, in the hope that the model would be able to capture more complex relationships. Unfortunately, the correct predictions are still 4 out of 8. `test3`, `test4` and `test6` are still recognised as the opposite sentiment, and the ambiguous `test5` is considered positive.\n",
        "##[Test 5](https://github.com/EMGrua/MN5002/blob/Giulia_Midulla_23330406/Section%202/Section_2_Giulia_Midulla_23330406_Test_5.ipynb)\n",
        "In the fifth test I decided to retrace Test 2, since it yelded the best results, so I halved all hyperparameters again, expect for the epochs, to avoid undertraining the model. Unfortunately, the correct predictions are still 4 out of 8. The numbers make more sense than the other tests though, with the ambiguous `test5` outputting only `0.67` and the positive `test6` being recognised as a very light positive with `0.56`."
      ],
      "metadata": {
        "id": "Gmwtw762nHsR"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}